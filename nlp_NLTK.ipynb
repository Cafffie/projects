{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa46d06",
   "metadata": {},
   "source": [
    "# NLTK LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5278b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk \n",
    "\n",
    "#nltk.download(\"stopwords\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps= PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37422558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required library\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a268fc15",
   "metadata": {},
   "source": [
    "# Sentence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79fc1256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the first 10 stopwords\n",
    "stopword= stopwords.words('english')\n",
    "stopwords.words('english')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f0730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a text sequence to analyse\n",
    "test_sentence = \"This is my first test string. wow!! we are doing fine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76b97e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminate the punctuation in the form of characters\n",
    "no_punctuation= [char for char in test_sentence if char not in string.punctuation]\n",
    "#no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1313e5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0772686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is my first test string wow we are doing fine'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminate punctuation and print them as a sentence\n",
    "no_punctuation = ''.join(no_punctuation)\n",
    "no_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5c3582f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'my',\n",
       " 'first',\n",
       " 'test',\n",
       " 'string',\n",
       " 'wow',\n",
       " 'we',\n",
       " 'are',\n",
       " 'doing',\n",
       " 'fine']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split each word present in the sentence\n",
    "no_punctuation.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3310ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first', 'test', 'string', 'wow', 'fine']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now eliminate stopwords\n",
    "clean_sentence = [word for word in no_punctuation.split() if word.lower() not in stopword]\n",
    "clean_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab1718",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eb707b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e42866",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer= CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b80f91f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi, how are you?', 'Today is a good day.', 'This was an amazing experience']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1= \"Hi, how are you?\"\n",
    "doc2= \"Today is a good day.\"\n",
    "doc3= \"This was an amazing experience\"\n",
    "\n",
    "text= [doc1,doc2, doc3]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2209e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words= vectorizer.fit(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0da3e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = vectorizer.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aab21236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 12)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 10)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 11)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043dd9a6",
   "metadata": {},
   "source": [
    "# Pipeline and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed3bac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from pprint import pprint\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc484c6",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9033b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87db2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence= \"Hello world! This is sentence tokennizing.\"\n",
    "word= \"Hello World! This is word tokenizing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5247bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello world!', 'This is sentence tokennizing.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c57794bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'World', '!', 'This', 'is', 'word', 'tokenizing', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "112620d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'World', 'This', 'is', 'word', 'tokenizing']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word tokenizing and removing punctuation\n",
    "\n",
    "[words for words in word_tokenize(word) if words not in string.punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e2017",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d76de0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "578e68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence= \"An apple a day keeps diseases at bay. This is an interesting information. Glad to recieve this.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d66fddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= set(stopwords.words('english'))\n",
    "tokens = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd6b9368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An',\n",
       " 'apple',\n",
       " 'a',\n",
       " 'day',\n",
       " 'keeps',\n",
       " 'diseases',\n",
       " 'at',\n",
       " 'bay',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'interesting',\n",
       " 'information',\n",
       " '.',\n",
       " 'Glad',\n",
       " 'to',\n",
       " 'recieve',\n",
       " 'this',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1f3deaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An',\n",
       " 'apple',\n",
       " 'day',\n",
       " 'keeps',\n",
       " 'diseases',\n",
       " 'bay',\n",
       " 'This',\n",
       " 'interesting',\n",
       " 'information',\n",
       " 'Glad',\n",
       " 'recieve']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text= [word for word in tokens if not word in string.punctuation]\n",
    "clean_text= [word for word in clean_text if not word in stop_words]\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf5fe6",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d6820ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3662131",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer= WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cfae9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foot\n",
      "cactus\n",
      "goose\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"feet\"))\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d036064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loving\n",
      "love\n"
     ]
    }
   ],
   "source": [
    "#without a POS tag, lemmatizer assumes everything ia a noun\n",
    "print(lemmatizer.lemmatize(\"loving\"))\n",
    "print(lemmatizer.lemmatize(\"loving\", 'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45cc1a0",
   "metadata": {},
   "source": [
    "# POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7680c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ecff8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= '''\n",
    "        Text mining , also referred to as text data mining,\n",
    "        roughly equivalent to text analytics, is the process of deriving high \n",
    "        quality information from text.\n",
    "        High-quality information is typically derived through the devising of patterns \n",
    "        and trends through means such as statistical pattern learning\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "378e20c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens= sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34ae7c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4e765fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Text', 'NNP'), ('mining', 'NN'), (',', ','), ('also', 'RB'), ('referred', 'VBD'), ('text', 'JJ'), ('data', 'NN'), ('mining', 'NN'), (',', ','), ('roughly', 'RB'), ('equivalent', 'JJ'), ('text', 'NN'), ('analytics', 'NNS'), (',', ','), ('process', 'NN'), ('deriving', 'VBG'), ('high', 'JJ'), ('quality', 'NN'), ('information', 'NN'), ('text', 'NN'), ('.', '.')]\n",
      "[('High-quality', 'NNP'), ('information', 'NN'), ('typically', 'RB'), ('derived', 'VBD'), ('devising', 'VBG'), ('patterns', 'NNS'), ('trends', 'NNS'), ('means', 'VBZ'), ('statistical', 'JJ'), ('pattern', 'NN'), ('learning', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "for i in sent_tokens:\n",
    "    tokens= nltk.word_tokenize(i)\n",
    "    tokens= [w for w in tokens if not w in stop_words]\n",
    "    tagged= nltk.pos_tag(tokens)\n",
    "    \n",
    "    print(tagged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
